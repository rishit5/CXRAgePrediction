{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9bba7f43",
   "metadata": {
    "papermill": {
     "duration": 0.004426,
     "end_time": "2024-01-04T22:36:36.190784",
     "exception": false,
     "start_time": "2024-01-04T22:36:36.186358",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Age Prediction of Patients by Chest X-rays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8ac43e2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-04T22:36:36.199943Z",
     "iopub.status.busy": "2024-01-04T22:36:36.199654Z",
     "iopub.status.idle": "2024-01-04T22:36:41.521691Z",
     "shell.execute_reply": "2024-01-04T22:36:41.520538Z"
    },
    "papermill": {
     "duration": 5.329049,
     "end_time": "2024-01-04T22:36:41.524014",
     "exception": false,
     "start_time": "2024-01-04T22:36:36.194965",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision.io import read_image\n",
    "from torchvision.utils import save_image\n",
    "from torchvision.transforms import ToTensor, Compose, Resize, Grayscale, Normalize, Lambda\n",
    "import os\n",
    "import torchvision.transforms as T\n",
    "import pydicom\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import optim\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f6ff03e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-04T22:36:41.534316Z",
     "iopub.status.busy": "2024-01-04T22:36:41.533869Z",
     "iopub.status.idle": "2024-01-04T22:36:41.538163Z",
     "shell.execute_reply": "2024-01-04T22:36:41.537321Z"
    },
    "papermill": {
     "duration": 0.011581,
     "end_time": "2024-01-04T22:36:41.540126",
     "exception": false,
     "start_time": "2024-01-04T22:36:41.528545",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2a0d996",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-04T22:36:41.549486Z",
     "iopub.status.busy": "2024-01-04T22:36:41.549201Z",
     "iopub.status.idle": "2024-01-04T22:36:41.553397Z",
     "shell.execute_reply": "2024-01-04T22:36:41.552556Z"
    },
    "papermill": {
     "duration": 0.010946,
     "end_time": "2024-01-04T22:36:41.555289",
     "exception": false,
     "start_time": "2024-01-04T22:36:41.544343",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the training image directory and annotations csv\n",
    "train_img_dir = '/kaggle/input/minijsrtageprediction/XPAge01_RGB/XP/JPGs/'\n",
    "train_annotations_file = '/kaggle/input/minijsrtageprediction/XPAge01_RGB/XP/trainingdata.csv'\n",
    "\n",
    "# Define the testing image directory and annotations csv\n",
    "test_img_dir = '/kaggle/input/minijsrtageprediction/XPAge01_RGB/XP/JPGs/'\n",
    "test_annotations_file = '/kaggle/input/minijsrtageprediction/XPAge01_RGB/XP/testdata.csv'\n",
    "\n",
    "# Define the output classes here\n",
    "num_classes = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94ffaab9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-04T22:36:41.564467Z",
     "iopub.status.busy": "2024-01-04T22:36:41.564207Z",
     "iopub.status.idle": "2024-01-04T22:36:41.590619Z",
     "shell.execute_reply": "2024-01-04T22:36:41.589716Z"
    },
    "papermill": {
     "duration": 0.033109,
     "end_time": "2024-01-04T22:36:41.592487",
     "exception": false,
     "start_time": "2024-01-04T22:36:41.559378",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(test_annotations_file)\n",
    "df['age'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d519680",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-04T22:36:41.602299Z",
     "iopub.status.busy": "2024-01-04T22:36:41.602001Z",
     "iopub.status.idle": "2024-01-04T22:36:41.609160Z",
     "shell.execute_reply": "2024-01-04T22:36:41.608348Z"
    },
    "papermill": {
     "duration": 0.014444,
     "end_time": "2024-01-04T22:36:41.611083",
     "exception": false,
     "start_time": "2024-01-04T22:36:41.596639",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define a custom class for dataset \n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):\n",
    "        self.img_labels = pd.read_csv(annotations_file)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.img_dir + self.img_labels.iloc[idx, 0]\n",
    "        image = read_image(img_path)\n",
    "        image = T.ToPILImage() (image)\n",
    "        label = self.img_labels.iloc[idx, 1]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05bfbab2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-04T22:36:41.620442Z",
     "iopub.status.busy": "2024-01-04T22:36:41.620180Z",
     "iopub.status.idle": "2024-01-04T22:36:41.626254Z",
     "shell.execute_reply": "2024-01-04T22:36:41.625568Z"
    },
    "papermill": {
     "duration": 0.012833,
     "end_time": "2024-01-04T22:36:41.628101",
     "exception": false,
     "start_time": "2024-01-04T22:36:41.615268",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Definining the resnet18 model\n",
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "import torch.nn as nn\n",
    "class Resnet18Classifier(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(Resnet18Classifier, self).__init__()\n",
    "        self.resnet18 = resnet18(pretrained=True).eval()\n",
    "        num_ftrs = self.resnet18.fc.in_features\n",
    "        self.resnet18.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.softmax(self.resnet18(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "48184b81",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-04T22:36:41.637474Z",
     "iopub.status.busy": "2024-01-04T22:36:41.637217Z",
     "iopub.status.idle": "2024-01-04T22:36:41.649075Z",
     "shell.execute_reply": "2024-01-04T22:36:41.648378Z"
    },
    "papermill": {
     "duration": 0.018648,
     "end_time": "2024-01-04T22:36:41.650969",
     "exception": false,
     "start_time": "2024-01-04T22:36:41.632321",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Defining the transform for loading the data\n",
    "transform = Compose([\n",
    "    ToTensor(),\n",
    "    Lambda(lambda x: x.repeat(3,1,1)),\n",
    "    Resize(224)\n",
    "])\n",
    "\n",
    "# Defining the training dataset and data loader\n",
    "train_dataset = CustomDataset(\n",
    "    annotations_file=train_annotations_file,\n",
    "    img_dir=train_img_dir,\n",
    "    transform=transform,\n",
    ")\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "# Defining the testing dataset and data loader\n",
    "test_dataset = CustomDataset(\n",
    "    annotations_file=test_annotations_file,\n",
    "    img_dir=test_img_dir,\n",
    "    transform=transform\n",
    ")\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c6ba9d6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-04T22:36:41.660452Z",
     "iopub.status.busy": "2024-01-04T22:36:41.660196Z",
     "iopub.status.idle": "2024-01-04T22:36:42.477204Z",
     "shell.execute_reply": "2024-01-04T22:36:42.476402Z"
    },
    "papermill": {
     "duration": 0.823917,
     "end_time": "2024-01-04T22:36:42.479227",
     "exception": false,
     "start_time": "2024-01-04T22:36:41.655310",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
      "100%|██████████| 44.7M/44.7M [00:00<00:00, 182MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Resnet18Classifier(\n",
       "  (resnet18): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=512, out_features=100, bias=True)\n",
       "  )\n",
       "  (softmax): Softmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initializing the resnet18 classifier with number of output models\n",
    "resnet_18_classifier = Resnet18Classifier(num_classes).to(device)\n",
    "\n",
    "# Defining the loss_function and the optimizer\n",
    "loss_func = nn.BCELoss()\n",
    "optimizer = optim.Adam(resnet_18_classifier.parameters(), lr = 0.001)\n",
    "resnet_18_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "222c12b9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-04T22:36:42.490607Z",
     "iopub.status.busy": "2024-01-04T22:36:42.490296Z",
     "iopub.status.idle": "2024-01-04T22:36:42.494610Z",
     "shell.execute_reply": "2024-01-04T22:36:42.493804Z"
    },
    "papermill": {
     "duration": 0.012172,
     "end_time": "2024-01-04T22:36:42.496471",
     "exception": false,
     "start_time": "2024-01-04T22:36:42.484299",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def vectorize(x):\n",
    "    one_hot_vec = torch.zeros(100, dtype=torch.int8)\n",
    "    one_hot_vec[x] = 1\n",
    "    return one_hot_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8ed1a826",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-04T22:36:42.507750Z",
     "iopub.status.busy": "2024-01-04T22:36:42.507107Z",
     "iopub.status.idle": "2024-01-04T22:39:12.760046Z",
     "shell.execute_reply": "2024-01-04T22:39:12.758948Z"
    },
    "papermill": {
     "duration": 150.260728,
     "end_time": "2024-01-04T22:39:12.762103",
     "exception": false,
     "start_time": "2024-01-04T22:36:42.501375",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Loss: 0.0564\n",
      "Epoch [2/50], Loss: 0.0547\n",
      "Epoch [3/50], Loss: 0.0540\n",
      "Epoch [4/50], Loss: 0.0530\n",
      "Epoch [5/50], Loss: 0.0496\n",
      "Epoch [6/50], Loss: 0.0483\n",
      "Epoch [7/50], Loss: 0.0464\n",
      "Epoch [8/50], Loss: 0.0492\n",
      "Epoch [9/50], Loss: 0.0494\n",
      "Epoch [10/50], Loss: 0.0468\n",
      "Epoch [11/50], Loss: 0.0478\n",
      "Epoch [12/50], Loss: 0.0458\n",
      "Epoch [13/50], Loss: 0.0466\n",
      "Epoch [14/50], Loss: 0.0483\n",
      "Epoch [15/50], Loss: 0.0475\n",
      "Epoch [16/50], Loss: 0.0483\n",
      "Epoch [17/50], Loss: 0.0468\n",
      "Epoch [18/50], Loss: 0.0481\n",
      "Epoch [19/50], Loss: 0.0488\n",
      "Epoch [20/50], Loss: 0.0476\n",
      "Epoch [21/50], Loss: 0.0471\n",
      "Epoch [22/50], Loss: 0.0483\n",
      "Epoch [23/50], Loss: 0.0472\n",
      "Epoch [24/50], Loss: 0.0465\n",
      "Epoch [25/50], Loss: 0.0462\n",
      "Epoch [26/50], Loss: 0.0477\n",
      "Epoch [27/50], Loss: 0.0464\n",
      "Epoch [28/50], Loss: 0.0471\n",
      "Epoch [29/50], Loss: 0.0465\n",
      "Epoch [30/50], Loss: 0.0476\n",
      "Epoch [31/50], Loss: 0.0474\n",
      "Epoch [32/50], Loss: 0.0507\n",
      "Epoch [33/50], Loss: 0.0473\n",
      "Epoch [34/50], Loss: 0.0467\n",
      "Epoch [35/50], Loss: 0.0476\n",
      "Epoch [36/50], Loss: 0.0472\n",
      "Epoch [37/50], Loss: 0.0504\n",
      "Epoch [38/50], Loss: 0.0483\n",
      "Epoch [39/50], Loss: 0.0478\n",
      "Epoch [40/50], Loss: 0.0468\n",
      "Epoch [41/50], Loss: 0.0471\n",
      "Epoch [42/50], Loss: 0.0462\n",
      "Epoch [43/50], Loss: 0.0480\n",
      "Epoch [44/50], Loss: 0.0479\n",
      "Epoch [45/50], Loss: 0.0450\n",
      "Epoch [46/50], Loss: 0.0481\n",
      "Epoch [47/50], Loss: 0.0466\n",
      "Epoch [48/50], Loss: 0.0473\n",
      "Epoch [49/50], Loss: 0.0476\n",
      "Epoch [50/50], Loss: 0.0477\n",
      "Training finished\n"
     ]
    }
   ],
   "source": [
    "# Training the model\n",
    "num_epochs = 50\n",
    "for epoch in range(num_epochs):\n",
    "    for images, labels in train_loader:\n",
    "        one_hot_labels = torch.cat(list(map(vectorize, labels)))\n",
    "#         print(f\"Label is {labels[0]}\")\n",
    "        one_hot_labels = one_hot_labels.view((-1, 100))\n",
    "        one_hot_labels = one_hot_labels.to(torch.float32)\n",
    "#         print(f\"one_hot_labels is {one_hot_labels[0]}\")\n",
    "        images, labels = images.to(device), one_hot_labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = resnet_18_classifier(images)\n",
    "#         print(f\"Output is {outputs[0]}\")\n",
    "        loss = loss_func(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "print(\"Training finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "040dc87c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-04T22:39:12.780792Z",
     "iopub.status.busy": "2024-01-04T22:39:12.780485Z",
     "iopub.status.idle": "2024-01-04T22:39:20.691668Z",
     "shell.execute_reply": "2024-01-04T22:39:20.690544Z"
    },
    "papermill": {
     "duration": 7.922756,
     "end_time": "2024-01-04T22:39:20.693787",
     "exception": false,
     "start_time": "2024-01-04T22:39:12.771031",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy for age: 0.74\n"
     ]
    }
   ],
   "source": [
    "# Testing the model\n",
    "total = 0\n",
    "auc = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        one_hot_labels = torch.cat(list(map(vectorize, labels)))\n",
    "        one_hot_labels = one_hot_labels.view((-1, 100))\n",
    "        one_hot_labels = one_hot_labels.to(torch.float32)\n",
    "        images, labels = images.to(device), one_hot_labels.to(device)\n",
    "        outputs = resnet_18_classifier(images)\n",
    "        labels = labels.cpu().numpy()\n",
    "        outputs = outputs.cpu().numpy()\n",
    "        for i, row in enumerate(labels):\n",
    "            auc += roc_auc_score(row, outputs[i])\n",
    "            total += 1\n",
    "\n",
    "accuracy = auc / total\n",
    "print(f\"Test Accuracy for age: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74acaeb5",
   "metadata": {
    "papermill": {
     "duration": 0.008503,
     "end_time": "2024-01-04T22:39:20.714667",
     "exception": false,
     "start_time": "2024-01-04T22:39:20.706164",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 3927016,
     "sourceId": 6829743,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30559,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 169.254937,
   "end_time": "2024-01-04T22:39:22.145805",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-01-04T22:36:32.890868",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
